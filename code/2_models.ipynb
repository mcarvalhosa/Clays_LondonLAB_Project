{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2_models: Time-Slot Clustering & Demand Prediction\n",
    "\n",
    "**This notebook will:**\n",
    "1. Load the master dataset (`../data/processed/master.parquet`)  \n",
    "2. **Slot-level aggregation** to (venue, date, hour)  \n",
    "3. **Time-slot clustering**: elbow test + KMeans, plus optional NMF/HAC  \n",
    "4. **Demand prediction**: CatBoost & XGBoost on slot-level data  \n",
    "5. Save cluster labels & trained models for downstream use  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import joblib  # to save models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load “master” dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../data/processed/master.parquet\")\n",
    "print(\"MASTER:\", df.shape)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Aggregate to (venue, date, hour)\n",
    "\n",
    "- **n_searches**  = count of searches  \n",
    "- **n_bookings** = sum(was_booked)  \n",
    "- **booking_rate** = n_bookings / n_searches  \n",
    "- **avg_price**  = mean(Search Charge)  \n",
    "- **pct_avail**  = mean(Was Search Available)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract date/hour\n",
    "df[\"date\"] = df[\"Search At\"].dt.date\n",
    "df[\"hour\"] = df[\"Search At\"].dt.hour\n",
    "\n",
    "# group & agg\n",
    "slot = (\n",
    "    df\n",
    "    .groupby([\"Venue Name\",\"date\",\"hour\"], as_index=False)\n",
    "    .agg(\n",
    "        n_searches   = (\"Context ID\",\"count\"),\n",
    "        n_bookings   = (\"was_booked\",\"sum\"),\n",
    "        avg_price    = (\"Search Charge\",\"mean\"),\n",
    "        pct_avail    = (\"Was Search Available\",\"mean\")\n",
    "    )\n",
    ")\n",
    "slot[\"booking_rate\"] = slot[\"n_bookings\"] / slot[\"n_searches\"]\n",
    "\n",
    "print(\"SLOT-AGG:\", slot.shape)\n",
    "slot.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Elbow Test: KMeans on `booking_rate`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "Ks = list(range(1,11))\n",
    "X = slot[[\"booking_rate\"]].values\n",
    "\n",
    "for k in Ks:\n",
    "    km = KMeans(n_clusters=k, random_state=42)\n",
    "    km.fit(X)\n",
    "    inertia.append(km.inertia_)\n",
    "\n",
    "plt.plot(Ks, inertia, \"-o\")\n",
    "plt.xlabel(\"k clusters\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.title(\"Elbow Plot on booking_rate\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Alternative Clustering: NMF & HAC\n",
    "\n",
    "We’ll run **NMF** and **Agglomerative** as fall-backs:\n",
    "- **NMF**: non-negative factorization on `booking_rate`  \n",
    "- **HAC**: hierarchical clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMF (1-component for simplicity)\n",
    "nmf = NMF(n_components=1, random_state=42)\n",
    "W = nmf.fit_transform(X)\n",
    "slot[\"nmf_comp\"] = W[:,0]\n",
    "\n",
    "# HAC (3 clusters example)\n",
    "hac = AgglomerativeClustering(n_clusters=3)\n",
    "slot[\"hac_cluster\"] = hac.fit_predict(X)\n",
    "\n",
    "# compute silhouette for HAC\n",
    "sil = silhouette_score(X, slot[\"hac_cluster\"])\n",
    "print(\"HAC silhouette:\", round(sil,3))\n",
    "\n",
    "slot.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Final KMeans (k=3)\n",
    "\n",
    "We’ll stick with k=3 (“off_peak/peak/super_peak”), but you can adjust.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=3, random_state=42)\n",
    "slot[\"km_cluster\"] = km.fit_predict(X)\n",
    "\n",
    "# Map cluster → labels (tweak order if needed)\n",
    "label_map = {0:\"off_peak\", 1:\"peak\", 2:\"super_peak\"}\n",
    "slot[\"slot_label\"] = slot[\"km_cluster\"].map(label_map)\n",
    "\n",
    "# Persist clusters\n",
    "slot[[\"Venue Name\",\"date\",\"hour\",\"slot_label\"]].to_csv(\n",
    "    \"../data/processed/time_slot_clusters.csv\", index=False\n",
    ")\n",
    "print(\"✅ Clusters saved → data/processed/time_slot_clusters.csv\")\n",
    "slot.head(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prepare Data for Demand Modeling\n",
    "\n",
    "- Merge cluster labels back to **slot**,  \n",
    "- Build features: hour, day_of_week, is_weekend, avg_price, pct_avail, cluster  \n",
    "- Target = booking_rate  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge clustering back to slot\n",
    "# (we already have it in slot; just rename)\n",
    "dfm = slot.copy()\n",
    "\n",
    "# add day_of_week & is_weekend\n",
    "dfm[\"day_of_week\"] = pd.to_datetime(dfm[\"date\"]).dt.dayofweek  # Mon=0\n",
    "dfm[\"is_weekend\"]  = dfm[\"day_of_week\"].isin([5,6]).astype(int)\n",
    "\n",
    "# select features & target\n",
    "features = [\n",
    "    \"hour\",\"day_of_week\",\"is_weekend\",\n",
    "    \"avg_price\",\"pct_avail\"\n",
    "] + [\"km_cluster\"]\n",
    "X = dfm[features]\n",
    "y = dfm[\"booking_rate\"]\n",
    "\n",
    "print(\"MODEL DATA:\", X.shape, y.shape)\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Train CatBoost Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CatBoostRegressor(\n",
    "    iterations=200,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    verbose=False,\n",
    "    random_seed=42\n",
    ")\n",
    "cat.fit(X_train, y_train, eval_set=(X_test,y_test))\n",
    "print(\"CatBoost RMSE:\", np.sqrt(((cat.predict(X_test)-y_test)**2).mean()))\n",
    "\n",
    "# save model\n",
    "joblib.dump(cat, \"../code/models/catboost_model.pkl\")\n",
    "print(\"✅ CatBoost model saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Train XGBoost Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    random_state=42,\n",
    "    verbosity=0\n",
    ")\n",
    "xgb.fit(X_train, y_train)\n",
    "print(\"XGBoost RMSE:\", np.sqrt(((xgb.predict(X_test)-y_test)**2).mean()))\n",
    "\n",
    "# save model\n",
    "joblib.dump(xgb, \"../code/models/xgboost_model.pkl\")\n",
    "print(\"✅ XGBoost model saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models are Complete ✅\n",
    "\n",
    "- **Clusters** → `data/processed/time_slot_clusters.csv`  \n",
    "- **Models** saved in `code/models/`  \n",
    "- Next: **Optimization** in `code/optimize/`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
